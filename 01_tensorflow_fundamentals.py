# -*- coding: utf-8 -*-
"""01_tensorflow_fundamentals.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W8uJIOuhAgbHqnLTxMzCIHauGqxNINp-

##in this notebook convering fundamentals  concepts of tensor using tensorflow

we going cover like
* introducation to tensor
* getting infromation from tensor
* manipulating tensors
* tensor & numpy

## introducation to tensor
"""

import tensorflow as tf
print(tf.__version__)

#create tensor with constant
scalar = tf.constant(10)
scalar

#check the dimensions
scalar.ndim

vector = tf.constant([1,2])
vector

vector.ndim



matrix = tf.constant([[1,2],[3,2]])
matrix

matrix.ndim

#create a tensor for  3 diamension
tensors = tf.constant([
    [
    [1,2,3],[1,32,2],[2,1,3],

    ],
    [
     [1,2,3],[1,32,2],[2,1,3],

     ],
 [
     [1,2,3],[1,32,2],[2,1,3],
 ]
    ])
tensors

tensors.ndim



"""what we created sofar


*  Sacalr is a single number
*  vector a number with direction
*  matrix is 2-dimensional array of number
*  tenor: an n-dimesnional array of number(where n is any , 0- dimesnional tensor is scalar, 1-dimesnional tensor is vector)

"""



"""Create tensor with tf.varibles


"""

#creating same tensor with tf.varibals() as above
changeable_tensor = tf.Variable([10,7])
unchangeable_tensor = tf.constant([10,7])
changeable_tensor,unchangeable_tensor

#  changeable_tensor[1].assign(10)
# changeable_tensor
# unchangeable_tensor[1].assign(10)
# unchangeable_tensor

"""
# Random tensor
"""

random_1 = tf.random.Generator.from_seed(42)
random_1 = random_1.normal(shape=(3,3))
random_2 = tf.random.Generator.from_seed(42)
random_2 = random_2.normal(shape=(3,3))
random_1,random_2,random_1==random_2

"""#suffel the order


"""

not_suffel_order = tf.constant([[1,3],[2,3],[1,4]])
not_suffel_order

tf.random.shuffle(not_suffel_order)

"""#creating tensor with numpy

"""

tf.ones([3,2])

import numpy as np
nummpyA = np.arange(0,30,dtype=np.int32)
nummpyA

A = tf.constant(nummpyA, shape=(10,3))
A

A.ndim

"""###Getting information about tensors
when dealing with tensor you probaly have aware following attributes
* Shape
* Rant
* Axis on diamension
* Size
"""

#crearte rank 4 tensor (4 diamension)

rank_four = tf.zeros([2,3,4,5])
rank_four

rank_four.shape,rank_four.ndim,tf.size(rank_four)

#Get various  attributes of tenosor
print("Database of every element :",rank_four.dtype)
print("Numbers of dimensions :",rank_four.ndim)
print("Shape of tensor :",rank_four.shape)
print("Database of the 0 aizs :",rank_four.shape[0])
print("Total number of element in our tensor :",tf.size(rank_four).numpy())

rank_2_tensor = tf.constant([[1,2],[3,4]])
rank_2_tensor.shape, rank_2_tensor.ndim

#Get the last item of each of row of our rank 2 element
rank_2_tensor[:,-1]



"""###manipulation of tenosr(tensor operation)
** basic operation **
`+` `-` `X` `/`

"""

#you can add value to tesnor using addtional operator and other operator also
tensor = tf.constant([[1,2],[1,4]])
tensor  = tensor + 10
tensor

#we can use inbuild method also
tensor = tf.multiply(tensor,10)
tensor

"""###Matrix multiplication
in machin learning matrix multiplication is most common in tensor operation

There are two rules our tensor (or matrices) need to fulfil if we're going to matrix multiply them:


1. The inner dimesnion must match.
2. The Resulting matrix has the shape of the outer dimesnion.
"""

#matrix multiplication in tensorflow
print(tensor)
tf.matmul(tensor,tensor)

#create tensor (3,2)
#we can multiplication if outer is match to inner ex:(2,3)(3,2) or (3,2)(2,3)
# if not we can reshape this.
x = tf.constant([[1,2],[3,4],[4,3] ])
y = tf.constant([[1,2],[3,4],[4,3] ])
x,y

tf.reshape(y,shape=(2,3))
tf.matmul(x,tf.reshape(y,shape=(2,3)))

x.shape,y.shape

"""#try matrix multiplication with transpose rather then reshape

**dot product**
matrix mulitpulation is alos referred to the dot product.

you can perfrom matri multiplicationn using:
* `tf.matmul()`
* `tf.tensordot()`
"""

#Perform dot product on X and Y  (require X and Y to be traspoed)
x,y

tf.matmul(x,tf.transpose(y))

tf.matmul(x,tf.reshape(y,shape=(2,3)))

#check the value of Y , reshape y and tranpose y
print("Normal Y:")
print(y,"\n")
print("reshape Y:")
print(tf.reshape(y,(2,3)),"\n")
print("tranpose Y:")
print(tf.transpose(y),"\n")

"""Generaly in matrix multiplication of two tensor and one of the aexs doesn't work we can choose tranpose rather then reshape to matrix for satify the matrix multiplication rules.

###Change the Datatype of tensor
"""

# prompt: get tf version

tf.__version__

B  = tf.constant([1.7,7.4])
B, B.dtype

C = tf.cast(B,dtype=tf.float16)
C,C.dtype

"""####Arrgregating tensor
 Arregration tensor: Combining many values into a small number.
"""

D = tf.constant([[-2,-1],[-3,-4]])
D

tf.abs(D)

"""Lets go through the following form of aggregation:



*   Get the min of tensor.
*   Get the max of tensor.
*   Get the mean of tensor.
*   Get the sum of tenosr.





"""

#create a random tensor
E = tf.constant(np.random.randint(0,100,size=50))
E

#find min
tf.reduce_min(E)

#find max
tf.reduce_max(E)

#find mean
tf.reduce_mean(E)

#find sum
tf.reduce_sum(E)



#second way
import tensorflow_probability as tfp
tfp.stats.variance(E)

#find stander devlation
tf.math.reduce_std(tf.cast(E,dtype=tf.float32))

#find the positonal maximum and minimum
tf.random.set_seed(50)
F = tf.random.uniform(shape=[50])
F

#find the max value
tf.argmax(F)

F[tf.argmax(F)]

tf.reduce_max(F)

#find min
tf.reduce_min(F)

"""###Squazzing the tensor (remove all single dimeantions)

"""

# create tensor to get start
G = tf.constant(tf.random.uniform(shape=[50]),shape=(1,1,1,1,50))
G

G_squazee = tf.squeeze(G)
G_squazee

G_squazee.shape

"""###ONE-HOT Encoding the tensor

"""

#creating the list of indices
some_list = [0,1,2,3,4]
tf.one_hot(some_list,depth=5)

tf.one_hot(some_list,depth=5,on_value="N",off_value="I")

"""###Tensor and Numpy
Tensor interacts beatuiful with Numpy arrays
One of the main diffrent between tensorflow tenosr and numpy tensorflow tensor run on GPU and TPU (for faster numeric
"""

J = tf.constant(np.array([1,3,4]))
J

#conver back tensor to numpy
np.array(J)
J.numpy(),type(J.numpy())

numpy_J = tf.constant(np.array([1,2,3]));
numpy_T = tf.constant([2,3,4]);
numpy_J.dtype,numpy_T.dtype

"""###Finding acess to GPU

"""

import tensorflow as tf
tf.config.list_physical_devices("GPU")

!nvidia-smi

###if you have access to CUDA-enabled GPU, TensorFlow will automatlicly use it whenever possible.

!git clone https://github.com/NITIN9694/TensorFlow-Learning.git

# Commented out IPython magic to ensure Python compatibility.
# %cd repo TensorFlow-Learning

!git add

!git